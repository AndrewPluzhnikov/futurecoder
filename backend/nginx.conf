# worker_processes 1;

user nobody nogroup;
# 'user nobody nobody;' for systems with 'nobody' as a group instead
pid /tmp/nginx.pid;
error_log /tmp/nginx.error.log;

events {
  worker_connections 1024; # increase if you have lots of clients
  accept_mutex off; # set to 'on' if nginx worker_processes > 1
  use epoll;
}

http {
  include mime.types;
  # fallback in case we can't determine a type
  default_type application/octet-stream;
  access_log /tmp/nginx.access.log combined;
  sendfile on;

  upstream app_server {
    # fail_timeout=0 means we always retry an upstream even if it failed
    # to return a good HTTP response

    server 127.0.0.1:8000 fail_timeout=0;
  }

  server {
    listen 3000 default_server deferred;
    client_max_body_size 10M;

    keepalive_timeout 5;

    # Requests forwarded by the load balancer that were originally HTTP
    # should get redirected to HTTPS
    # The load balancer manages the HTTPS, the server accepts HTTP only
    if ($http_x_forwarded_proto = 'http') {
      return 301 https://$host$request_uri;
    }

    location /static_backend {
        alias /usr/src/app/backend/static;
    }

    location /f/ {
        alias /usr/src/app/frontend/build/;
    }

    location / {
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      # enable this if and only if you use HTTPS
      #proxy_set_header X-Forwarded-Proto https;
      proxy_set_header Host $http_host;
      # we don't want nginx trying to do something clever with
      # redirects, we set the Host: header above already.
      proxy_redirect off;
      proxy_pass http://app_server;
    }

  }
}
